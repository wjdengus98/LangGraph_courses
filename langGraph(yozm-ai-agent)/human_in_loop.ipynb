{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 휴먼 인 더 루프 - 프로그램 시스템 사에서 사람의 개입이 필요한 부분\n",
    "\n",
    "1. 중단점(BreakPoint): AI가 인간의 개입이 필요한 시점을 인식\n",
    "2. 컨텍스트 제공: 인간이 올바른 결정을 내릴 수 있도록 충분한 정보 제공\n",
    "3. 피드백 수집: 구조화된 방식으로 인간의 입력 수정\n",
    "4. 재개(Resume): 인간의 결정에 따라 워크플로 계속 진행\n",
    "\n",
    "해당 내용은 요즘 ai 에이전트 개발 llM RAG ADK MCP LangChain A2A (저자: 박승규) 에서 첨부하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리\n",
    "from typing import Literal\n",
    "from langgraph.graph import StateGraph, START,END\n",
    "from langchain.chat_models import init_chat_model\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pydantic을 사용한 state 정의 \n",
    "class AgentState(BaseModel):\n",
    "    user_message: str = Field(default=\"\", description=\"사용자 입력 작업\")\n",
    "    task_details: str = Field(default=\"\", description=\"직업 상세 정보\")\n",
    "    response: str = Field(default=\"\", description=\"응답 결과\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#노드 함수 정의\n",
    "def get_llm_response_node(state: AgentState, llm):\n",
    "    \"\"\"LLM과 상호작용하여 응답을 생성하거나, 추가 정보를 요청하는 노드\"\"\"\n",
    "    details = state.task_details\n",
    "    \n",
    "    if details:\n",
    "        print(f\"\\n상세 정보를 바탕으로 작업 실행: {details}\")\n",
    "        prompt = f\"다음 요청에 따라 보고서를 작성해주세요: {details}\"\n",
    "    else:\n",
    "        task = state.user_message\n",
    "        print(f\"\\n작업 실행: {task} 작업을 수행합니다...\")\n",
    "        # ② LLM에게 상세 정보를 묻는 질문을 하도록 유도하고, 반드시 '?'로 끝내도록 지시\n",
    "        prompt = f\"'{task}' 작업을 수행하려고 합니다. 어떤 종류의 보고서가 필요한지, 구체적인 주제는 무엇인지 질문해주세요. 추가 정보가 필요하면, 반드시 응답의 마지막을 물음표('?')로 끝내주세요.\"\n",
    "    \n",
    "    response = llm.invoke(prompt).content\n",
    "    \n",
    "    print(\"---- LLM 응답 ----\")\n",
    "    print(response)\n",
    "    print(\"------------------\")\n",
    "    \n",
    "    return {\"response\": response, \"task_details\": \"\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ③ 사람의 입력을 받는 노드\n",
    "def get_task_details_node(state:AgentState) -> AgentState:\n",
    "    \"\"\"LLM의 질문에 대한 사용자 답변을 입력받는 노드\"\"\"\n",
    "    print(\"\\nLLM의 질문에 답변해주세요.\")\n",
    "    user_input = input(\"답변: \")\n",
    "    return {\"task_details\" : user_input}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#조건부 분기 노드\n",
    "def check_llm_response(state: AgentState) -> Literal[\"get_details\", \"end\"]:\n",
    "    \"\"\"LLM의 응답이 질문인지 확인하여 다음 단계를 결정합니다.\"\"\"\n",
    "    print(\"LLM 응답 분석 중.....\")\n",
    "    if state.response.strip().endswith('?'):\n",
    "        print(\"LLM이 추가 정보를 요청했습니다. 사용자 입력을 받습니다.\")\n",
    "        return \"get_details\"\n",
    "    print(\"최종 보고서가 생성되었습니다. 워크플로우를 종료합니다.\")\n",
    "    return \"end\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph():\n",
    "    \"\"\"human-in-the-loop 워크플로우 그래프를 생성합니다.\"\"\"\n",
    "    # 그래프 전체에서 사용할 LLM 모델을 초기화 합니다.\n",
    "    llm = init_chat_model(\"gpt-5-mini\", model_provider=\"openai\")\n",
    "    \n",
    "    def get_llm_response_with_llm(state):\n",
    "        return get_llm_response_node(state, llm)\n",
    "    \n",
    "    workflow = StateGraph(AgentState)\n",
    "    workflow.add_node(\"get_llm_response\", get_llm_response_with_llm)\n",
    "    workflow.add_node(\"get_details\", get_task_details_node)\n",
    "    \n",
    "    workflow.add_edge(START, \"get_llm_response\")\n",
    "    workflow.add_conditional_edges(\n",
    "        \"get_llm_response\",\n",
    "        check_llm_response,\n",
    "        {\n",
    "            \"get_details\":\"get_details\",\n",
    "            \"end\" : END\n",
    "        }\n",
    "    )\n",
    "    workflow.add_edge(\"get_details\", \"get_llm_response\")\n",
    "    return workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== LangGraph Human-in-the-loop 간소화 예제 ===\n",
      "\n",
      "\n",
      "작업 실행: 블로그 글 작성 작업을 수행합니다...\n",
      "---- LLM 응답 ----\n",
      "블로그 글 작성을 정확히 도와드리려면 아래 항목들을 알려주세요:\n",
      "\n",
      "- 어떤 종류의 글(정보성/분석/가이드/리뷰/사례연구/SEO용/랜딩페이지 등)을 원하시나요?  \n",
      "- 구체적인 주제나 핵심 키워드는 무엇인가요?  \n",
      "- 목표 독자(연령대, 관심사, 전문성 수준 등)는 어떻게 되나요?  \n",
      "- 글의 목표는 무엇인가요?(트래픽 증가, 리드 생성, 브랜드 인지도, 제품 홍보 등)  \n",
      "- 원하는 글 길이(대략 단어 수 또는 분량)는 얼마인가요?  \n",
      "- 톤과 스타일 선호(친근한/전문적인/중립적/카주얼 등)는 무엇인가요?  \n",
      "- 반드시 포함해야 할 핵심 포인트나 메시지가 있나요?  \n",
      "- 목차나 섹션 구성에 대한 선호가 있나요(예: 서론/문제제기/해결책/사례/결론 등)?  \n",
      "- SEO 요구사항(주요 키워드, 보조 키워드, 메타디스크립션, 제목 태그 등)이 있나요?  \n",
      "- 이미지, 차트, 표 등 시각 자료가 필요한가요? 직접 제공하실 건가요, 제가 추천할까요?  \n",
      "- 참고할 자료나 인용해야 할 출처(URL, 논문, 내부 문서 등)이 있나요?  \n",
      "- 내부 링크 또는 외부 링크 연결 정책(특정 페이지로 연결 등)이 있나요?  \n",
      "- 인용 형식(APA, MLA 등)이나 각주 필요 여부는요?  \n",
      "- 표절 검사나 원본성 기준(예: 유사도 몇 % 이하)이 있나요?  \n",
      "- 납기일(완료 희망일)과 수정 가능 횟수 제약이 있나요?  \n",
      "- 참고할 예시 글이나 선호하는 블로그(스타일 예시) URL이 있다면 알려주실 수 있나요?  \n",
      "- 다국어 번역이나 국제화(영어 버전 등)가 필요하신가요?  \n",
      "- 해당 글의 공개 범위는 내부용인가요, 외부 공개(게시)용인가요?  \n",
      "- 추가로 특별히 원하시는 사항이나 제약 조건이 있나요?\n",
      "\n",
      "답변을 주시면 그에 맞춰 초안 구조와 예상 소요시간을 제안드리겠습니다?\n",
      "------------------\n",
      "LLM 응답 분석 중.....\n",
      "LLM이 추가 정보를 요청했습니다. 사용자 입력을 받습니다.\n",
      "\n",
      "LLM의 질문에 답변해주세요.\n",
      "\n",
      "상세 정보를 바탕으로 작업 실행: AI 에이전트에 대한 기술 블로그\n",
      "---- LLM 응답 ----\n",
      "제목: AI 에이전트(Agent) 기술 블로그 — 개념, 아키텍처, 구현과 현업 적용\n",
      "\n",
      "요약\n",
      "AI 에이전트는 주어진 환경에서 관찰을 바탕으로 목표를 달성하기 위해 행동을 선택·실행하는 소프트웨어 구성요소다. 본 블로그는 에이전트의 정의와 분류, 핵심 컴포넌트, 주요 아키텍처(전통적·ML 기반·LLM 기반), 구현 도구와 인프라, 평가 지표와 안전성 고려사항, 실제 적용 사례와 구현 팁을 기술적 관점에서 정리한다.\n",
      "\n",
      "1. 에이전트란?\n",
      "- 정의: 에이전트는 환경(환경 센서/입력)을 관찰(observation, state)하고, 정책(policy)에 따라 행동(action)을 선택해 환경에 영향을 미치는 시스템이다. 목표(목적 함수, 보상)를 가지고 학습하거나 규칙 기반으로 동작한다.\n",
      "- 핵심 속성: 자율성, 목표 지향성, 적응성(학습), 상호작용 능력(환경/다른 에이전트).\n",
      "\n",
      "2. 에이전트의 분류\n",
      "- 반응형(reactive) 에이전트: 현재 관찰에 즉시 반응. 상태 기억/계획 최소. 예: 규칙 기반 챗봇의 단순 패턴 매칭.\n",
      "- 모델 기반/계획형(deliberative) 에이전트: 내부 모델을 유지하고 미래를 계획. 예: 고전 플래닝(STRIPS) 에이전트.\n",
      "- 학습형 에이전트: 강화학습(RL), 지도학습 혼합. 정책을 데이터로부터 학습.\n",
      "- 하이브리드 에이전트: 규칙 + ML, 계획 + 학습 결합.\n",
      "- 멀티에이전트 시스템(MAS): 여러 에이전트가 상호작용(협력/경쟁). 응용: 자율주행 차량, 분산 로봇.\n",
      "\n",
      "3. 핵심 컴포넌트(모듈화 관점)\n",
      "- 감지(Perception): 센서/입력 처리(이미지, 텍스트, 로그). 전처리/특징 추출(예: CNN, Transformer).\n",
      "- 상태 표현(State/Belief): 현재 상태 또는 확률적 신념(belief state)을 유지(Partially Observable 환경에서 중요).\n",
      "- 의사결정(Policy/Planner): 행동을 선택하는 알고리즘(정책, 계획기). RL의 정책 네트워크, 검색 기반 플래너 등.\n",
      "- 학습(Learning): 온라인/오프라인 학습, 모델 업데이트, 경험 재생 버퍼 등.\n",
      "- 액추에이션(Action/Execution): 실제 명령 전송, API 호출, 로봇 제어 등.\n",
      "- 메타관리(Memory/Knowledge): 장기 메모리, 캐시, 외부 지식베이스(RAG), 툴 사용 모듈(tool use).\n",
      "- 안전/감시(Safety & Monitoring): 피드백 루프, 제약 검사, 위험 탐지, 롤백.\n",
      "\n",
      "4. 주요 아키텍처와 기법\n",
      "- 규칙 기반 + 상태 머신: 안전·예측 가능성이 중요할 때 사용. 단순하지만 확장성 제한.\n",
      "- 강화학습(RL): Q-learning, DQN, PPO, SAC 등. 연속/고차원 행동공간에서 유용. 시뮬레이터 필요.\n",
      "- 모방 학습(Behavioral cloning, Inverse RL): 인간 데이터로부터 정책 학습.\n",
      "- 모델 기반 RL: 환경 모델을 학습해 상향식 계획에 사용.\n",
      "- LLM 기반 에이전트:\n",
      "  - 프롬프트 기반(Chain-of-Thought, ReAct): LLM을 추론 엔진으로 쓰고, 툴 호출(계산기, 검색, DB)에 연결해 복합 작업 수행.\n",
      "  - RAG(Retrieval-Augmented Generation): 문서/지식베이스에서 정보 검색 후 LLM에 제공.\n",
      "  - 멀티모달 LLM 에이전트: Vision-Language 모델로 이미지+텍스트 인퍼런스 및 툴 제어.\n",
      "- 하이브리드: 예를 들어 안전 관련 부분은 규칙 기반, 전략적 의사결정은 RL/LLM으로 처리.\n",
      "\n",
      "5. 실무 구현 스택(예시)\n",
      "- 시뮬레이션/환경: OpenAI Gym, DeepMind Lab, CARLA(자율주행), MuJoCo(물리).\n",
      "- RL 라이브러리: Stable Baselines3, RLlib, Acme, TF-Agents.\n",
      "- LLM 툴체인: Hugging Face Transformers, OpenAI API, Anthropic Claude.\n",
      "- 에이전트 프레임워크: LangChain(툴/체인 관리), OpenAI Agents / BabyAGI(실험적), Microsoft Semantic Kernel.\n",
      "- 인프라: Docker/Kubernetes, Redis(메타데이터·큐), Kafka(이벤트 스트리밍), Ray(분산 처리).\n",
      "- 모니터링: Prometheus, Grafana, Sentry(오류 추적).\n",
      "\n",
      "6. 평가 지표(환경·응용별)\n",
      "- 성능: 누적 보상, 성공률, 정확도, 응답 시간(latency).\n",
      "- 효율성: 샘플 효율성(데이터/시뮬레이션 사용량), 계산 비용(추론/학습 FLOPs).\n",
      "- 안전성/견고성: 실패율, 예외 상황 거동, 보안 취약점(데이터 조작·악용).\n",
      "- 사용자 경험(UX): 응답의 유용성, 일관성, 편의성.\n",
      "\n",
      "7. 안전·윤리·구조적 고려사항\n",
      "- 잘못된 행동 예방: 제약 기반 안전 검사(validator), 시뮬레이션에서 광범위한 테스트.\n",
      "- 목표 정렬(Alignment): 보상 설계의 역설(어뷰징), RL에서의 보상 설계 문제.\n",
      "- 프라이버시: 사용자 데이터 저장·처리 규정 준수(최소화, 익명화).\n",
      "- 투명성 및 설명가능성(XAI): 결정 이유 제공(특히 규제 대상 응용).\n",
      "- 악용 방지: 권한 관리, 툴 접근 제어, 입력 검증.\n",
      "\n",
      "8. 간단한 예제(LLM 기반 툴 사용 에이전트, 의사 코드)\n",
      "- 목적: 외부 검색 툴을 사용해 질의 답변 생성.\n",
      "(의사 코드)\n",
      "agent_loop(input):\n",
      "  context = retrieve_docs(input)  # RAG\n",
      "  prompt = build_prompt(context, input)\n",
      "  response = LLM.generate(prompt)\n",
      "  if needs_tool(response):\n",
      "    tool_input = parse_tool_request(response)\n",
      "    tool_output = call_tool(tool_input)\n",
      "    context.append(tool_output)\n",
      "    prompt = build_prompt(context, input)\n",
      "    response = LLM.generate(prompt)\n",
      "  return finalize(response)\n",
      "\n",
      "(현업 팁) 툴 호출은 명시적 인터페이스(함수명+정형화된 입력/출력)를 사용해 LLM이 안전하게 외부 행동을 하도록 제한한다.\n",
      "\n",
      "9. 사례 연구(요약)\n",
      "- 고객지원 봇: RAG로 사내 문서 검색 + LLM으로 정답 생성 + 규칙 기반 거짓말 차단(예: 모르는 경우 “정보 없음” 리턴).\n",
      "- 자율주행 에이전트: 시뮬레이션에서 RL로 주행 정책 학습 + 규칙 기반 안전 레이어(비상 정지).\n",
      "- 코드 작성 어시스턴트: LLM + 실행 환경(sandbox) 연동으로 코드를 생성 후 테스트/검증.\n",
      "\n",
      "10. 구현 가이드(체크리스트)\n",
      "- 목표·성공 지표 정의: KPI 및 실패 시 안전 동작 명시.\n",
      "- 데이터·시뮬레이터 확보: 현실적 분포 커버.\n",
      "- 아키텍처 결정: 규칙/학습/혼합 여부, 툴 인터페이스 설계.\n",
      "- 평가 파이프라인: 자동화된 단위/통합 테스트, 시나리오 기반 시뮬레이션.\n",
      "- 모니터링·롤백: 이상 탐지, 모델 버전 관리, A/B 테스트.\n",
      "- 규제·보안 검토: 개인정보, 액세스 제어, 감사로그.\n",
      "\n",
      "11. 최신 동향과 전망\n",
      "- LLM 기반 에이전트의 확산: 프롬프트 설계, 툴 연동, 메타-학습이 핵심.\n",
      "- 오프라인·샘플 효율 RL 기법(모델 기반, 잠재 공간 플래닝) 발전.\n",
      "- 멀티모달·상호작용 능력 강화: 실제 환경과의 긴 루프(감지→행동→피드백)에서 성능 향상.\n",
      "- 안전·검증 도구의 중요성 증대: 형식적 검증, 시뮬레이션 기반 보증.\n",
      "\n",
      "참고 문헌·자료\n",
      "- Sutton & Barto, Reinforcement Learning: An Introduction\n",
      "- LangChain docs, Hugging Face Transformers, OpenAI API docs\n",
      "- 최근 논문: ReAct, Chain-of-Thought, Retrieval-Augmented Generation 관련 논문들\n",
      "\n",
      "맺음말\n",
      "AI 에이전트 구축은 도메인 요구사항·안전 제약·운영 인프라를 종합적으로 고려해야 하는 엔지니어링 작업이다. 단일 기술(예: LLM 또는 RL)로 모든 문제를 해결하기보다는 규칙·학습·툴 연동을 적절히 조합해 목표에 맞는 아키텍처를 설계하는 것이 실무에서 성공하는 핵심이다.\n",
      "\n",
      "원하시면 다음을 제공해 드립니다:\n",
      "- 특정 도메인(예: 금융 고객지원, 물류 로봇)용 에이전트 설계 템플릿\n",
      "- LangChain을 이용한 LLM 에이전트의 코드 예제(실제 구현)\n",
      "- RL 기반 에이전트(예: PPO) 학습 파이프라인 예제\n",
      "\n",
      "원하시는 것을 알려주세요.\n",
      "------------------\n",
      "LLM 응답 분석 중.....\n",
      "최종 보고서가 생성되었습니다. 워크플로우를 종료합니다.\n",
      "\n",
      "--- 워크플로우 종료 ---\n",
      "최종 응답:\n",
      "제목: AI 에이전트(Agent) 기술 블로그 — 개념, 아키텍처, 구현과 현업 적용\n",
      "\n",
      "요약\n",
      "AI 에이전트는 주어진 환경에서 관찰을 바탕으로 목표를 달성하기 위해 행동을 선택·실행하는 소프트웨어 구성요소다. 본 블로그는 에이전트의 정의와 분류, 핵심 컴포넌트, 주요 아키텍처(전통적·ML 기반·LLM 기반), 구현 도구와 인프라, 평가 지표와 안전성 고려사항, 실제 적용 사례와 구현 팁을 기술적 관점에서 정리한다.\n",
      "\n",
      "1. 에이전트란?\n",
      "- 정의: 에이전트는 환경(환경 센서/입력)을 관찰(observation, state)하고, 정책(policy)에 따라 행동(action)을 선택해 환경에 영향을 미치는 시스템이다. 목표(목적 함수, 보상)를 가지고 학습하거나 규칙 기반으로 동작한다.\n",
      "- 핵심 속성: 자율성, 목표 지향성, 적응성(학습), 상호작용 능력(환경/다른 에이전트).\n",
      "\n",
      "2. 에이전트의 분류\n",
      "- 반응형(reactive) 에이전트: 현재 관찰에 즉시 반응. 상태 기억/계획 최소. 예: 규칙 기반 챗봇의 단순 패턴 매칭.\n",
      "- 모델 기반/계획형(deliberative) 에이전트: 내부 모델을 유지하고 미래를 계획. 예: 고전 플래닝(STRIPS) 에이전트.\n",
      "- 학습형 에이전트: 강화학습(RL), 지도학습 혼합. 정책을 데이터로부터 학습.\n",
      "- 하이브리드 에이전트: 규칙 + ML, 계획 + 학습 결합.\n",
      "- 멀티에이전트 시스템(MAS): 여러 에이전트가 상호작용(협력/경쟁). 응용: 자율주행 차량, 분산 로봇.\n",
      "\n",
      "3. 핵심 컴포넌트(모듈화 관점)\n",
      "- 감지(Perception): 센서/입력 처리(이미지, 텍스트, 로그). 전처리/특징 추출(예: CNN, Transformer).\n",
      "- 상태 표현(State/Belief): 현재 상태 또는 확률적 신념(belief state)을 유지(Partially Observable 환경에서 중요).\n",
      "- 의사결정(Policy/Planner): 행동을 선택하는 알고리즘(정책, 계획기). RL의 정책 네트워크, 검색 기반 플래너 등.\n",
      "- 학습(Learning): 온라인/오프라인 학습, 모델 업데이트, 경험 재생 버퍼 등.\n",
      "- 액추에이션(Action/Execution): 실제 명령 전송, API 호출, 로봇 제어 등.\n",
      "- 메타관리(Memory/Knowledge): 장기 메모리, 캐시, 외부 지식베이스(RAG), 툴 사용 모듈(tool use).\n",
      "- 안전/감시(Safety & Monitoring): 피드백 루프, 제약 검사, 위험 탐지, 롤백.\n",
      "\n",
      "4. 주요 아키텍처와 기법\n",
      "- 규칙 기반 + 상태 머신: 안전·예측 가능성이 중요할 때 사용. 단순하지만 확장성 제한.\n",
      "- 강화학습(RL): Q-learning, DQN, PPO, SAC 등. 연속/고차원 행동공간에서 유용. 시뮬레이터 필요.\n",
      "- 모방 학습(Behavioral cloning, Inverse RL): 인간 데이터로부터 정책 학습.\n",
      "- 모델 기반 RL: 환경 모델을 학습해 상향식 계획에 사용.\n",
      "- LLM 기반 에이전트:\n",
      "  - 프롬프트 기반(Chain-of-Thought, ReAct): LLM을 추론 엔진으로 쓰고, 툴 호출(계산기, 검색, DB)에 연결해 복합 작업 수행.\n",
      "  - RAG(Retrieval-Augmented Generation): 문서/지식베이스에서 정보 검색 후 LLM에 제공.\n",
      "  - 멀티모달 LLM 에이전트: Vision-Language 모델로 이미지+텍스트 인퍼런스 및 툴 제어.\n",
      "- 하이브리드: 예를 들어 안전 관련 부분은 규칙 기반, 전략적 의사결정은 RL/LLM으로 처리.\n",
      "\n",
      "5. 실무 구현 스택(예시)\n",
      "- 시뮬레이션/환경: OpenAI Gym, DeepMind Lab, CARLA(자율주행), MuJoCo(물리).\n",
      "- RL 라이브러리: Stable Baselines3, RLlib, Acme, TF-Agents.\n",
      "- LLM 툴체인: Hugging Face Transformers, OpenAI API, Anthropic Claude.\n",
      "- 에이전트 프레임워크: LangChain(툴/체인 관리), OpenAI Agents / BabyAGI(실험적), Microsoft Semantic Kernel.\n",
      "- 인프라: Docker/Kubernetes, Redis(메타데이터·큐), Kafka(이벤트 스트리밍), Ray(분산 처리).\n",
      "- 모니터링: Prometheus, Grafana, Sentry(오류 추적).\n",
      "\n",
      "6. 평가 지표(환경·응용별)\n",
      "- 성능: 누적 보상, 성공률, 정확도, 응답 시간(latency).\n",
      "- 효율성: 샘플 효율성(데이터/시뮬레이션 사용량), 계산 비용(추론/학습 FLOPs).\n",
      "- 안전성/견고성: 실패율, 예외 상황 거동, 보안 취약점(데이터 조작·악용).\n",
      "- 사용자 경험(UX): 응답의 유용성, 일관성, 편의성.\n",
      "\n",
      "7. 안전·윤리·구조적 고려사항\n",
      "- 잘못된 행동 예방: 제약 기반 안전 검사(validator), 시뮬레이션에서 광범위한 테스트.\n",
      "- 목표 정렬(Alignment): 보상 설계의 역설(어뷰징), RL에서의 보상 설계 문제.\n",
      "- 프라이버시: 사용자 데이터 저장·처리 규정 준수(최소화, 익명화).\n",
      "- 투명성 및 설명가능성(XAI): 결정 이유 제공(특히 규제 대상 응용).\n",
      "- 악용 방지: 권한 관리, 툴 접근 제어, 입력 검증.\n",
      "\n",
      "8. 간단한 예제(LLM 기반 툴 사용 에이전트, 의사 코드)\n",
      "- 목적: 외부 검색 툴을 사용해 질의 답변 생성.\n",
      "(의사 코드)\n",
      "agent_loop(input):\n",
      "  context = retrieve_docs(input)  # RAG\n",
      "  prompt = build_prompt(context, input)\n",
      "  response = LLM.generate(prompt)\n",
      "  if needs_tool(response):\n",
      "    tool_input = parse_tool_request(response)\n",
      "    tool_output = call_tool(tool_input)\n",
      "    context.append(tool_output)\n",
      "    prompt = build_prompt(context, input)\n",
      "    response = LLM.generate(prompt)\n",
      "  return finalize(response)\n",
      "\n",
      "(현업 팁) 툴 호출은 명시적 인터페이스(함수명+정형화된 입력/출력)를 사용해 LLM이 안전하게 외부 행동을 하도록 제한한다.\n",
      "\n",
      "9. 사례 연구(요약)\n",
      "- 고객지원 봇: RAG로 사내 문서 검색 + LLM으로 정답 생성 + 규칙 기반 거짓말 차단(예: 모르는 경우 “정보 없음” 리턴).\n",
      "- 자율주행 에이전트: 시뮬레이션에서 RL로 주행 정책 학습 + 규칙 기반 안전 레이어(비상 정지).\n",
      "- 코드 작성 어시스턴트: LLM + 실행 환경(sandbox) 연동으로 코드를 생성 후 테스트/검증.\n",
      "\n",
      "10. 구현 가이드(체크리스트)\n",
      "- 목표·성공 지표 정의: KPI 및 실패 시 안전 동작 명시.\n",
      "- 데이터·시뮬레이터 확보: 현실적 분포 커버.\n",
      "- 아키텍처 결정: 규칙/학습/혼합 여부, 툴 인터페이스 설계.\n",
      "- 평가 파이프라인: 자동화된 단위/통합 테스트, 시나리오 기반 시뮬레이션.\n",
      "- 모니터링·롤백: 이상 탐지, 모델 버전 관리, A/B 테스트.\n",
      "- 규제·보안 검토: 개인정보, 액세스 제어, 감사로그.\n",
      "\n",
      "11. 최신 동향과 전망\n",
      "- LLM 기반 에이전트의 확산: 프롬프트 설계, 툴 연동, 메타-학습이 핵심.\n",
      "- 오프라인·샘플 효율 RL 기법(모델 기반, 잠재 공간 플래닝) 발전.\n",
      "- 멀티모달·상호작용 능력 강화: 실제 환경과의 긴 루프(감지→행동→피드백)에서 성능 향상.\n",
      "- 안전·검증 도구의 중요성 증대: 형식적 검증, 시뮬레이션 기반 보증.\n",
      "\n",
      "참고 문헌·자료\n",
      "- Sutton & Barto, Reinforcement Learning: An Introduction\n",
      "- LangChain docs, Hugging Face Transformers, OpenAI API docs\n",
      "- 최근 논문: ReAct, Chain-of-Thought, Retrieval-Augmented Generation 관련 논문들\n",
      "\n",
      "맺음말\n",
      "AI 에이전트 구축은 도메인 요구사항·안전 제약·운영 인프라를 종합적으로 고려해야 하는 엔지니어링 작업이다. 단일 기술(예: LLM 또는 RL)로 모든 문제를 해결하기보다는 규칙·학습·툴 연동을 적절히 조합해 목표에 맞는 아키텍처를 설계하는 것이 실무에서 성공하는 핵심이다.\n",
      "\n",
      "원하시면 다음을 제공해 드립니다:\n",
      "- 특정 도메인(예: 금융 고객지원, 물류 로봇)용 에이전트 설계 템플릿\n",
      "- LangChain을 이용한 LLM 에이전트의 코드 예제(실제 구현)\n",
      "- RL 기반 에이전트(예: PPO) 학습 파이프라인 예제\n",
      "\n",
      "원하시는 것을 알려주세요.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "     print(\"=== LangGraph Human-in-the-loop 간소화 예제 ===\\n\")\n",
    "     app = create_graph()\n",
    "     final_state = app.invoke(AgentState(user_message=\"블로그 글 작성\"))\n",
    "     print(\"\\n--- 워크플로우 종료 ---\")\n",
    "     print(\"최종 응답:\")\n",
    "     print(final_state[\"response\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
